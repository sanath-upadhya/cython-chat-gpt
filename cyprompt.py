import inspect
import utils as util
import openai
import subprocess
import os
import shutil
import importlib
import time
import random
from hypothesis import example, given, strategies as st

def cyprompt(useCode=False, useDoc=False, tests=[]):
    def cyprompt_decorator(func):
        def inner1(*args, **kwargs):
            original_function_name = func.__name__
            chat_gpt_input_string = get_input_string_for_chatgpt(func, useCode, useDoc)
            reply = chat_gpt_reply(chat_gpt_input_string)
            cython_code = process_chat_gpt_reply(reply)

            print(cython_code)
            function_name = get_function_name(cython_code)
            
            create_tmp_folder()
            try:
                create_cython_file_and_compile(cython_code)

                function = load_module(function_name)
            except:
                raise Exception("The function generated by chat GPT is wrong!!")
            finally:
                delete_tmp_folder()
            
            #Do testing here
            try:
                for ind_test in tests:
                    real_ind_test = process_test_case(ind_test, original_function_name, function_name)
                    test_factory(function, real_ind_test)
            except AssertionError:
                raise Exception("The function generated by chat GPT is wrong!!")
            
            finally:
                delete_tmp_folder()

            start = time.time()
            returned_value = function(*args, **kwargs)
            end = time.time()
            content = "Time by cython code is " + str(end-start)
            util.write_to_file(content)
            print("Time by cython code is " + str(end-start))

            delete_tmp_folder()
            # returning the value to the original frame
            return returned_value            
        return inner1
    return cyprompt_decorator

def process_test_case(ind_test, original_function_name, function_name):
    if isinstance(ind_test, str):
        real_ind_test = ind_test.replace(original_function_name, function_name)
        return real_ind_test
    elif isinstance(ind_test, tuple):
        real_ind_test = []
        real_ind_test.append(ind_test[0])
        test_case = ind_test[1].replace(original_function_name, function_name)
        real_ind_test.append(test_case)
        return tuple(real_ind_test)
    
def test_factory(function, test_arg):
    function_name = function.__name__
    global_dict = {}
    global_dict[function_name] = function
    global_dict['given'] = given
    global_dict['st'] = st
    if isinstance(test_arg, str):
        loc = {}
        p_test = f"""
def test():
    assert {test_arg}

test() 
"""
        exec(p_test, global_dict, loc)

    elif isinstance(test_arg, tuple):
        actual_string = "actual = " + test_arg[0]
        loc = {}
        exec(actual_string, globals(), loc)
        
        h_test = f"""
@given({test_arg[0]})
def test(n):
    assert {test_arg[1]}

test()
"""
        loc = {}
        exec(h_test, global_dict, loc)
        

def delete_tmp_folder():
    #Remove all the tmp so files and folders generated
    current_dir = os.getcwd()
    build_dir = current_dir + "/build"
    tmp_dir = current_dir + "/tmp"

    if os.path.exists(build_dir):
        shutil.rmtree(build_dir)
    
    if os.path.exists(tmp_dir):
        shutil.rmtree(tmp_dir)

    files_in_dir = os.listdir(current_dir)
    for file in files_in_dir:
        if file.endswith(".so"):
            os.remove(os.path.join(current_dir, file))

    pass

def load_module(function_name):
    module = importlib.import_module('custom_cython')
    function = getattr(module,function_name)
    return function

def create_tmp_folder():
    current_directory = os.getcwd()
    new_directory = current_directory + '/tmp'

    if not os.path.exists(new_directory):
        os.mkdir(new_directory)


def get_function_name(cython_code):
    for line in cython_code:
        if(line.startswith(('def ','cdef ','cpdef '))):
            list = line.split()
            for element in list:
                if "(" in element:
                    name_of_function = element.split('(')
                    return name_of_function[0]

def process_chat_gpt_reply(reply):
    lines_in_list = reply.split('\n')
    lines_in_code = []
    final_lines_in_code = []
    code_start = False
    number_of_code = 0
    for line in lines_in_list:
        print(line)
        if line == "" and number_of_code == 1 and len(lines_in_code) != 0:
            code_start = toggle_docstring(code_start)
            number_of_code = number_of_code + 1
        elif line.startswith(('```','%%cython')):
            code_start = toggle_docstring(code_start)
            if code_start:
                number_of_code = number_of_code + 1
            continue
        else:
            if(code_start and number_of_code == 1):
                if line.startswith('#'):
                    continue
                elif line =="":
                    continue
                else:    
                    lines_in_code.append(line)

    for line in lines_in_code:
        if line.startswith('%%cython'):
            continue
        else:
            final_lines_in_code.append(line)

    return final_lines_in_code

def create_cython_file_and_compile(cython_code):
    f= open("tmp/custom_cython.pyx","w+")
    for line in cython_code:
        f.write(line + '\n')
    f.close()
    create_setup_file()
    cython_compile = subprocess.run(util.CYTHON_COMPILE_EXEC_COMMAND, stdout=subprocess.DEVNULL)


def create_setup_file():
    f=open("tmp/setup.py","w+")
    for line in util.CYTHON_SETUP_FILE:
        f.write(line + '\n')
    
    f.close()


def chat_gpt_reply(chat_gpt_input_string):
    openai.api_key = open("key.txt","r").read().strip('\n')
    completion = completions_with_backoff(model="gpt-3.5-turbo",messages=[{"role":"user","content":chat_gpt_input_string}] )
    reply_content = completion.choices[0].message.content
    return reply_content

def get_input_string_for_chatgpt(func, useCode, useDoc):
    chat_gpt_input_string = ""
    if useDoc and useCode:
        chat_gpt_input_string = util.CYTHON_CODE_REQUEST_DOC_STRING + func.__doc__
        lines_in_code = get_code_lines(func)
        str_lines_in_code = '\n'.join(lines_in_code)
        chat_gpt_input_string = chat_gpt_input_string + '\n' + util.CYTHON_CODE_REQUEST_PYTHON_DOC_STRING + '\n' + str_lines_in_code
    elif (useDoc):
        chat_gpt_input_string = util.CYTHON_CODE_REQUEST_DOC_STRING + func.__doc__

    elif (useCode):
        lines_in_code = get_code_lines(func)
        str_lines_in_code = '\n'.join(lines_in_code)
        chat_gpt_input_string = util.CYTHON_CODE_REQUEST_PYTHON_STRING +'\n'+ str_lines_in_code
    else:
        pass
    return chat_gpt_input_string


def get_code_lines(func):
    lines = inspect.getsource(func)
    lines_in_list = lines.split('\n')
    is_docstring = False
    lines_in_code = []
    for line in lines_in_list:
        if(line.startswith('@cyprompt')):
            continue
        else:
            if(line.__contains__('"""')):
                is_docstring = toggle_docstring(is_docstring)
                continue
            else:
                if(is_docstring):
                    continue
                else:
                    lines_in_code.append(line)

    return lines_in_code

def toggle_docstring(is_docstring):
    if (is_docstring):
        return False
    else:
        return True
    

# This code is taken from the following location:
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb
def retry_with_exponential_backoff(
    func,
    initial_delay: float = 1,
    exponential_base: float = 2,
    jitter: bool = True,
    max_retries: int = 10,
    errors: tuple = (openai.error.RateLimitError,),
):
    """Retry a function with exponential backoff."""

    def wrapper(*args, **kwargs):
        # Initialize variables
        num_retries = 0
        delay = initial_delay

        # Loop until a successful response or max_retries is hit or an exception is raised
        while True:
            try:
                return func(*args, **kwargs)

            # Retry on specified errors
            except errors as e:
                # Increment retries
                num_retries += 1

                # Check if max retries has been reached
                if num_retries > max_retries:
                    raise Exception(
                        f"Maximum number of retries ({max_retries}) exceeded."
                    )

                # Increment the delay
                delay *= exponential_base * (1 + jitter * random.random())

                # Sleep for the delay
                time.sleep(delay)

            # Raise exceptions for any errors not specified
            except Exception as e:
                raise e

    return wrapper


@retry_with_exponential_backoff
def completions_with_backoff(**kwargs):
    return openai.ChatCompletion.create(**kwargs)

